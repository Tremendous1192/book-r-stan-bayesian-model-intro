{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f57034e",
   "metadata": {},
   "source": [
    "# 5-9-動的一般化線形モデル：ポアソン分布を仮定した例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea0271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Dynamic GLM with Poisson observations (NumPyro version)\n",
    "# Requirements:\n",
    "#   pip install numpyro arviz jax jaxlib pandas matplotlib seaborn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "#from jax.config import config as jax_config\n",
    "#jax_config.update(\"jax_enable_x64\", True)\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d833da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 1) Data loading & quick plot\n",
    "# ------------------------------\n",
    "# CSV読み込み（pandas使用、.locは不使用）\n",
    "csv_path = \"5-9-1-fish-num-ts.csv\"\n",
    "fish_ts = pd.read_csv(csv_path)\n",
    "fish_ts[\"date\"] = pd.to_datetime(fish_ts[\"date\"])\n",
    "\n",
    "# 計算結果は print() で表示\n",
    "print(\"Head of data:\")\n",
    "print(fish_ts.head(3))\n",
    "\n",
    "# 英語ラベルで可視化（matplotlib / seaborn）\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "axes[0].plot(fish_ts[\"date\"], fish_ts[\"fish_num\"])\n",
    "axes[0].set_ylabel(\"Catch count\")\n",
    "axes[0].set_title(\"Time series of catch count\")\n",
    "\n",
    "axes[1].plot(fish_ts[\"date\"], fish_ts[\"temperature\"])\n",
    "axes[1].set_ylabel(\"Temperature (°C)\")\n",
    "axes[1].set_xlabel(\"Date\")\n",
    "axes[1].set_title(\"Time series of temperature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac239f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 2) Prepare arrays\n",
    "# ------------------------------\n",
    "y = fish_ts[\"fish_num\"].to_numpy(dtype=np.int64)\n",
    "ex = fish_ts[\"temperature\"].to_numpy(dtype=np.float64)\n",
    "T = int(fish_ts.shape[0])\n",
    "\n",
    "print(f\"Number of time points T = {T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffaf3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 3) NumPyro model (dynamic GLM)\n",
    "# -----------------------------------\n",
    "def dglm_poisson(y=None, ex=None, T=None):\n",
    "    # Priors\n",
    "    s_z = numpyro.sample(\"s_z\", dist.HalfNormal(1.0))   # drift sd\n",
    "    s_r = numpyro.sample(\"s_r\", dist.HalfNormal(1.0))   # random effect sd\n",
    "    b   = numpyro.sample(\"b\",   dist.Normal(0.0, 5.0))  # regression coef\n",
    "\n",
    "    # Initial states (weakly-informative)\n",
    "    mu_1 = numpyro.sample(\"mu_1\", dist.Normal(0.0, 10.0))\n",
    "    mu_2 = numpyro.sample(\"mu_2\", dist.Normal(0.0, 10.0))\n",
    "    mu_seq = [mu_1, mu_2]\n",
    "\n",
    "    # i.i.d. random effects r_t\n",
    "    with numpyro.plate(\"time\", int(T)):\n",
    "        r = numpyro.sample(\"r\", dist.Normal(0.0, s_r))\n",
    "\n",
    "    # State evolution: mu_t ~ Normal(2*mu_{t-1} - mu_{t-2}, s_z), for t>=3\n",
    "    for t in range(2, int(T)):\n",
    "        mu_hat = 2.0 * mu_seq[t-1] - mu_seq[t-2]\n",
    "        mu_t = numpyro.sample(f\"mu_{t+1}\", dist.Normal(mu_hat, s_z))\n",
    "        mu_seq.append(mu_t)\n",
    "\n",
    "    mu = jnp.stack(mu_seq)  # shape (T,)\n",
    "\n",
    "    # Linear predictor and Poisson likelihood\n",
    "    ex_arr = jnp.array(ex)\n",
    "    lam_log = mu + b * ex_arr + r\n",
    "    lam = jnp.exp(lam_log)\n",
    "\n",
    "    # Deterministic nodes (generated quantities in Stan)\n",
    "    numpyro.deterministic(\"lambda_exp\", lam)\n",
    "    numpyro.deterministic(\"lambda_smooth\", jnp.exp(mu + b * ex_arr))\n",
    "    numpyro.deterministic(\"lambda_smooth_fix\", jnp.exp(mu + b * jnp.mean(ex_arr)))\n",
    "\n",
    "    # Observation\n",
    "    if y is not None:\n",
    "        numpyro.sample(\"y\", dist.Poisson(lam), obs=jnp.array(y))\n",
    "    else:\n",
    "        numpyro.sample(\"y\", dist.Poisson(lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f617906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 4) (Optional) visualize model graph\n",
    "#     * use NumPyro's built-in rendering if available\n",
    "# -----------------------------------\n",
    "try:\n",
    "    # NumPyro 0.14+ provides render_model at top-level\n",
    "    from numpyro.render_model import render_model   # type: ignore\n",
    "    dot = render_model(dglm_poisson, model_args=(), model_kwargs={\"y\": y, \"ex\": ex, \"T\": T})\n",
    "    # In notebooks, just `dot` displays. Here, we only announce its creation.\n",
    "    print(\"Rendered model graph (Graphviz Digraph object) created via numpyro.render_model.\")\n",
    "except Exception as e:\n",
    "    print(\"Model rendering skipped (numpyro.render_model not available):\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f88b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 5) Run MCMC (matching Stan settings)\n",
    "# -----------------------------------\n",
    "rng_key = jax.random.PRNGKey(1)\n",
    "nuts = NUTS(dglm_poisson, target_accept_prob=0.99, max_tree_depth=15)\n",
    "\n",
    "# Stan側: iter=8000, warmup=2000, thin=6 => 有効サンプル ~1000/ch.\n",
    "# こちらも num_warmup=2000, num_samples=1000, thinning=6, chains=4 に合わせる\n",
    "mcmc = MCMC(nuts, num_warmup=2000, num_samples=1000, num_chains=4, thinning=6, progress_bar=True)\n",
    "mcmc.run(rng_key, y=y, ex=ex, T=T)\n",
    "mcmc.print_summary()  # 計算結果の表示は print() 経由"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d472fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 6) Convert to ArviZ InferenceData\n",
    "#     (禁止条件に従い、mcmc/observed_data/sample_stats 引数は使用しない)\n",
    "# -----------------------------------\n",
    "idata = az.from_numpyro(posterior=mcmc)\n",
    "print(\"InferenceData groups:\", idata.groups())\n",
    "\n",
    "# R-hat 参考: （az.rhat は Dataset を返す）\n",
    "rhat_ds = az.rhat(idata)\n",
    "print(\"R-hat (selected):\")\n",
    "print(rhat_ds[[\"b\", \"s_z\", \"s_r\"]])  # Datasetのまま print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae1210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 7) Posterior predictive samples with Predictive\n",
    "#     ※ batch_ndims=1 to indicate merged chain dimension\n",
    "# -----------------------------------\n",
    "rng_key_ppc = jax.random.PRNGKey(123)\n",
    "#posterior_samples = mcmc.get_samples(group_by_chain=True)\n",
    "\n",
    "#predictive = Predictive(\n",
    "#    dglm_poisson,\n",
    "#    posterior_samples=posterior_samples,\n",
    "#    return_sites=[\"y\", \"lambda_exp\", \"lambda_smooth\", \"lambda_smooth_fix\"],\n",
    "#    batch_ndims=1  # チェイン結合を示す 1\n",
    "#)\n",
    "# 変更後（OK）\n",
    "posterior_samples = mcmc.get_samples(group_by_chain=False)  # ← チェインを結合して (num_samples, …) にする\n",
    "predictive = Predictive(dglm_poisson,\n",
    "                        posterior_samples=posterior_samples,\n",
    "                        return_sites=[\"y\",\"lambda_exp\",\"lambda_smooth\",\"lambda_smooth_fix\"],\n",
    "                        batch_ndims=1)  # ← 1 で整合\n",
    "ppc_samples = predictive(rng_key_ppc, y=None, ex=ex, T=T)\n",
    "\n",
    "# InferenceData に posterior_predictive を追加（禁止引数は使わない）\n",
    "idata = az.from_numpyro(\n",
    "    posterior=mcmc,\n",
    "    posterior_predictive=ppc_samples\n",
    ")\n",
    "print(\"Added posterior_predictive to InferenceData.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d40238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 8) Parameter posterior visualization (ArviZ)\n",
    "#     * az.plot_posterior は hdi_prob を使用（credible_interval禁止）\n",
    "# -----------------------------------\n",
    "az.plot_posterior(\n",
    "    idata,\n",
    "    var_names=[\"b\", \"s_z\", \"s_r\"],\n",
    "    hdi_prob=0.95\n",
    ")\n",
    "plt.suptitle(\"Posterior distributions (95% HDI)\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Trace plots (参考、ArviZ)\n",
    "az.plot_trace(idata, var_names=[\"b\", \"s_z\", \"s_r\"])\n",
    "plt.suptitle(\"Trace plots\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Forest plot（group引数は使用しない）\n",
    "az.plot_forest(idata, var_names=[\"b\", \"s_z\", \"s_r\"])\n",
    "plt.title(\"Forest plot of parameters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 9) Posterior predictive check\n",
    "#     * group=\"posterior\" を指定\n",
    "# -----------------------------------\n",
    "az.plot_ppc(idata, group=\"posterior\", data_pairs={\"y\": \"y\"})\n",
    "plt.suptitle(\"Posterior Predictive Check\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDI を計算（Dataset が返る）\n",
    "#hdi_ds = az.hdi(idata.posterior_predictive, hdi_prob=0.94)\n",
    "\n",
    "# 変数名を指定して DataArray を取り出し、hdi 座標で lower/higher を選択（←重要）\n",
    "#low_exp  = hdi_ds[\"lambda_exp\"].sel(hdi=\"lower\").values\n",
    "#high_exp = hdi_ds[\"lambda_exp\"].sel(hdi=\"higher\").values\n",
    "\n",
    "#low_smooth  = hdi_ds[\"lambda_smooth\"].sel(hdi=\"lower\").values\n",
    "#high_smooth = hdi_ds[\"lambda_smooth\"].sel(hdi=\"higher\").values\n",
    "\n",
    "#low_fix  = hdi_ds[\"lambda_smooth_fix\"].sel(hdi=\"lower\").values\n",
    "#high_fix = hdi_ds[\"lambda_smooth_fix\"].sel(hdi=\"higher\").values\n",
    "\n",
    "# 以降の fill_between は長さが一致するので OK\n",
    "#fig, axes = plt.subplots(3, 1, figsize=(11, 9), sharex=True)\n",
    "#axes[0].fill_between(fish_ts[\"date\"].values, low_exp,  high_exp,  alpha=0.3, label=\"94% HDI\")\n",
    "#axes[1].fill_between(fish_ts[\"date\"].values, low_smooth,high_smooth,alpha=0.3, label=\"94% HDI\")\n",
    "#axes[2].fill_between(fish_ts[\"date\"].values, low_fix,  high_fix,  alpha=0.3, label=\"94% HDI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 10) State visualization (lambda_exp / smooth / smooth_fix)\n",
    "#      * HDI は az.hdi を使い、戻り値 Dataset から変数名指定で取り出す\n",
    "# -----------------------------------\n",
    "# 予測関連の配列（chain, draw, time）→ 事後中央値\n",
    "lam_exp = idata.posterior_predictive[\"lambda_exp\"].values  # (chain, draw, T)\n",
    "lam_smooth = idata.posterior_predictive[\"lambda_smooth\"].values\n",
    "lam_smooth_fix = idata.posterior_predictive[\"lambda_smooth_fix\"].values\n",
    "\n",
    "# 事後中央値\n",
    "med_exp = np.median(lam_exp.reshape(-1, T), axis=0)\n",
    "med_smooth = np.median(lam_smooth.reshape(-1, T), axis=0)\n",
    "med_smooth_fix = np.median(lam_smooth_fix.reshape(-1, T), axis=0)\n",
    "\n",
    "# 94% HDI を計算（Dataset が返る）\n",
    "hdi_ds = az.hdi(idata.posterior_predictive, hdi_prob=0.94)\n",
    "\n",
    "# 変数名を指定して DataArray を取り出し、hdi 座標で lower/higher を選択（←重要）\n",
    "low_exp  = hdi_ds[\"lambda_exp\"].sel(hdi=\"lower\").values\n",
    "high_exp = hdi_ds[\"lambda_exp\"].sel(hdi=\"higher\").values\n",
    "\n",
    "low_smooth  = hdi_ds[\"lambda_smooth\"].sel(hdi=\"lower\").values\n",
    "high_smooth = hdi_ds[\"lambda_smooth\"].sel(hdi=\"higher\").values\n",
    "\n",
    "low_fix  = hdi_ds[\"lambda_smooth_fix\"].sel(hdi=\"lower\").values\n",
    "high_fix = hdi_ds[\"lambda_smooth_fix\"].sel(hdi=\"higher\").values\n",
    "\n",
    "#hdi_exp = hdi_ds[\"lambda_exp\"].values  # shape (2, T) -> [low, high]\n",
    "#hdi_smooth = hdi_ds[\"lambda_smooth\"].values\n",
    "#hdi_smooth_fix = hdi_ds[\"lambda_smooth_fix\"].values\n",
    "\n",
    "\n",
    "# 図1: lambda_exp\n",
    "fig, axes = plt.subplots(3, 1, figsize=(11, 9), sharex=True)\n",
    "\n",
    "#axes[0].fill_between(fish_ts[\"date\"], hdi_exp[0], hdi_exp[1], alpha=0.3, label=\"94% HDI\")\n",
    "axes[0].fill_between(fish_ts[\"date\"].values, low_exp,  high_exp,  alpha=0.3, label=\"94% HDI\")\n",
    "axes[0].plot(fish_ts[\"date\"], med_exp, label=\"Median of state (all effects)\")\n",
    "axes[0].scatter(fish_ts[\"date\"], y, s=15, alpha=0.6, label=\"Observed\")\n",
    "axes[0].set_ylabel(\"Expected catch\")\n",
    "axes[0].set_title(\"State: lambda_exp (with random effect and covariate)\")\n",
    "axes[0].legend()\n",
    "\n",
    "# 図2: lambda_smooth\n",
    "#axes[1].fill_between(fish_ts[\"date\"], hdi_smooth[0], hdi_smooth[1], alpha=0.3, label=\"94% HDI\")\n",
    "axes[1].fill_between(fish_ts[\"date\"].values, low_smooth,high_smooth,alpha=0.3, label=\"94% HDI\")\n",
    "axes[1].plot(fish_ts[\"date\"], med_smooth, label=\"Median of state (no random effect)\")\n",
    "axes[1].scatter(fish_ts[\"date\"], y, s=15, alpha=0.6, label=\"Observed\")\n",
    "axes[1].set_ylabel(\"Expected catch\")\n",
    "axes[1].set_title(\"State: lambda_smooth (random effect removed)\")\n",
    "axes[1].legend()\n",
    "\n",
    "# 図3: lambda_smooth_fix\n",
    "#axes[2].fill_between(fish_ts[\"date\"], hdi_smooth_fix[0], hdi_smooth_fix[1], alpha=0.3, label=\"94% HDI\")\n",
    "axes[2].fill_between(fish_ts[\"date\"].values, low_fix,  high_fix,  alpha=0.3, label=\"94% HDI\")\n",
    "axes[2].plot(fish_ts[\"date\"], med_smooth_fix, label=\"Median of state (covariate fixed)\")\n",
    "axes[2].scatter(fish_ts[\"date\"], y, s=15, alpha=0.6, label=\"Observed\")\n",
    "axes[2].set_ylabel(\"Expected catch\")\n",
    "axes[2].set_xlabel(\"Date\")\n",
    "axes[2].set_title(\"State: lambda_smooth_fix (random effect removed, temperature fixed)\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6069933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 11) Print a concise parameter summary (with HDI)\n",
    "# -----------------------------------\n",
    "summary_df = az.summary(idata, var_names=[\"b\", \"s_z\", \"s_r\"], hdi_prob=0.95)\n",
    "print(\"Parameter summary (95% HDI):\")\n",
    "print(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
